# Exercise 1: Communication Style Comparison

## Comparing AutoGen and CrewAI Agent Communication

After running both `autogen_simple_demo.py` and `crewai_demo.py`, I observed significant differences in how agents communicate and pass information between each other. This document analyzes these differences.

---

## Summary Comparison

| Aspect | AutoGen | CrewAI |
|--------|---------|--------|
| **Communication Pattern** | Sequential with Context Passing | Sequential with Task Dependencies |
| **Data Flow** | Each agent reads previous output | Each agent builds on previous task results |
| **Conversation Style** | Prompt-based with context injection | Tool-based with structured inputs |
| **Output Structure** | Free-form text responses | Structured task outputs |
| **Agent Awareness** | Aware of previous agent's work | Aware through task context |
| **Flexibility** | High - agents can iterate | Moderate - follows task structure |

---

## AutoGen Communication Style

### My Observations:

When I ran the AutoGen demo, I noticed that each agent explicitly receives the previous agent's output in their prompt. The workflow manually passes context from one phase to the next.

```python
# Phase 1: ResearchAgent analyzes market
self.outputs["research"] = agent_response

# Phase 2: AnalysisAgent receives ResearchAgent's output
user_message = f"""Market research findings:
{self.outputs['research']}

Now identify market opportunities and gaps."""
```

### How Context is Passed:

Looking at the code, I can see that each phase manually injects the previous agent's output into the next agent's prompt:
```python
def phase_analysis(self):
    # AnalysisAgent receives research results
    user_message = f"""Market research findings:
{self.outputs['research']}  # â† Previous agent's output

Now identify market opportunities and gaps."""
```

This creates a conversational flow where agents build on each other's responses:
```
ResearchAgent: "Here are 3 competitors: HireVue, Pymetrics, Codility..."

AnalysisAgent: "Based on your research, I found 3 opportunities..."

BlueprintAgent: "Based on the opportunities you identified, here's my design..."

ReviewerAgent: "Looking at the blueprint, I recommend..."
```

### What I Noticed in the Code:

Every phase explicitly references previous work. For example:

```python
# Phase 3: Blueprint references Analysis
user_message = f"""Market Analysis:
{self.outputs['analysis']}  # â† Explicit reference

Create a product blueprint for our platform."""

# Phase 4: Review references Blueprint  
user_message = f"""Product Blueprint:
{self.outputs['blueprint']}  # â† Explicit reference

Provide strategic review and recommendations."""
```

### The Flow I Observed:
```
Phase 1 (Research) 
    â†“ [output stored]
Phase 2 (Analysis) â† reads Phase 1 output
    â†“ [output stored]
Phase 3 (Blueprint) â† reads Phase 2 output
    â†“ [output stored]
Phase 4 (Review) â† reads Phase 3 output
    â†“ [output stored]
Phase 5 (Marketing) â† reads Phase 3 & 4 outputs
```

### Output Example from My Run:

```
PHASE 1: MARKET RESEARCH
========================
[ResearchAgent is analyzing the market...]

[ResearchAgent Output]
The AI interview platform market includes:
- HireVue: Video interviews with AI analysis
- Pymetrics: Cognitive assessments
- Codility: Technical coding challenges
[...]

PHASE 2: OPPORTUNITY ANALYSIS
==============================
[AnalysisAgent is identifying opportunities...]

[AnalysisAgent Output]
Based on the market research provided, I identified:
1. Gap in holistic candidate evaluation
2. Need for better candidate experience
3. Opportunity for smaller companies
[...]
```

I noticed that each agent explicitly references what the previous agent said, making the conversation flow very clear.

---

## CrewAI Communication Style

### My Observations:

When I ran the CrewAI demo, the workflow felt different. Agents didn't explicitly receive previous outputs in their prompts. Instead, the framework seemed to handle context passing automatically.

```python
# Agents are created with specific roles and tools
flight_agent = Agent(role="Flight Specialist", tools=[search_flight_prices])
hotel_agent = Agent(role="Accommodation Specialist", tools=[search_hotel_options])

# Tasks reference other tasks as context
hotel_task = Task(
    description="Based on the trip dates from flight research...",
    agent=hotel_agent,
    context=[flight_task]  # â† Implicit dependency
)

# Crew executes sequentially
crew = Crew(
    agents=[flight_agent, hotel_agent, itinerary_agent, budget_agent],
    tasks=[flight_task, hotel_task, itinerary_task, budget_task],
    process="sequential"
)
```

### How It Works:

Looking at the code structure, I found that:
```python
def create_hotel_task(hotel_agent, destination: str, trip_dates: str):
    return Task(
        description=f"Based on the trip dates ({trip_dates}), find and recommend "
                   f"the top 3-4 REAL hotels...",
        agent=hotel_agent,
        # Note: No explicit context passing - CrewAI handles it
    )
```

I also noticed that agents use tools to gather information:

```python
@tool
def search_flight_prices(destination: str, departure_city: str) -> str:
    """Search for real flight prices and options to a destination."""
    return f"""Research task: Find flights from {departure_city} to {destination}..."""

# Agent uses the tool automatically
flight_agent = Agent(
    role="Flight Specialist",
    tools=[search_flight_prices],  # â† Agent has access to this tool
)
```

### Agent Definitions:

Each agent in CrewAI has a structured definition with role, goal, and backstory:

```python
Agent(
    role="Accommodation Specialist",  # â† Clear role
    goal="Suggest top-rated hotels considering amenities and value",  # â† Clear goal
    backstory="You are a seasoned accommodation expert...",  # â† Personality
    tools=[search_hotel_options],  # â† Capabilities
)
```

### The Workflow I Observed:
```
crew.kickoff() executes:
    â†“
Task 1: FlightAgent researches flights
    â†“ [CrewAI stores result]
Task 2: HotelAgent (automatically receives flight context)
    â†“ [CrewAI stores result]
Task 3: ItineraryAgent (automatically receives flight + hotel context)
    â†“ [CrewAI stores result]
Task 4: BudgetAgent (automatically receives all previous context)
    â†“
Final aggregated result
```

### Output Example from My Run:

```
ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: Research flights
    Status: Executing Task...
    â””â”€â”€ ğŸ”§ Using search_flight_prices
    
ğŸ¤– Agent Started: Flight Specialist
Task: Research and compile a list of REAL flight options...
[Agent Output]
Flight Options from New York to Iceland:
1. Icelandair - $450, 6hrs direct
2. United - $520, 8hrs (1 stop)
[...]

ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: Find hotels
    Status: Executing Task...
    â””â”€â”€ ğŸ”§ Using search_hotel_options

ğŸ¤– Agent Started: Accommodation Specialist
Task: Based on trip dates (from flight research), recommend hotels...
[Agent Output]
Based on the January 15-20 trip dates:
1. Hotel Borg - $180/night, 4.5â­
2. Canopy by Hilton - $220/night, 4.7â­
[...]
```

I noticed that agents reference context implicitly - "based on trip dates" - without me explicitly passing it. CrewAI handles this behind the scenes.

---

## Key Differences I Found

### Context Management

**AutoGen:**
```python
# Manual context passing
user_message = f"""Market research findings:
{self.outputs['research']}  # â† You manually inject context

Now identify opportunities."""
```

**CrewAI:**
```python
# Automatic context passing
Task(
    description="Based on the flight research, recommend hotels...",
    agent=hotel_agent,
    # CrewAI automatically provides previous task outputs
)
```

### Agent Communication Pattern

In AutoGen, agents "talk" to each other through prompts:
```
Agent A â†’ produces output â†’ stored in dict
                            â†“
Agent B â†’ receives output in prompt â†’ responds
```

In CrewAI, agents "work" on tasks that build on each other:
```
Agent A â†’ completes task â†’ CrewAI stores result
                           â†“
Agent B â†’ starts task â†’ CrewAI injects previous results â†’ completes
```

### My Thoughts on Flexibility

Based on what I've seen, AutoGen offers:
- âœ… Can easily modify what context each agent sees
- âœ… Can add conditional logic between phases
- âœ… Can have agents iterate or debate
- âŒ More code to write
- âŒ Manual output management

**CrewAI:**
- âœ… Less code - framework handles context
- âœ… Clear task structure
- âœ… Built-in tools system
- âŒ Less control over exact context
- âŒ Harder to add custom logic between tasks

---

## Practical Examples from the Code

### Example 1: AutoGen Marketing Phase

```python
def phase_marketing(self):
    """Phase 5: Marketing Strategy"""
    # Explicitly provides context from TWO previous phases
    user_message = f"""Product Blueprint:
{self.outputs['blueprint']}

Strategic Review:
{self.outputs['review']}

Develop a go-to-market strategy..."""
```

What I observed: The agent explicitly receives outputs from TWO previous phases (Blueprint AND Review).

### Example 2: CrewAI Budget Task

```python
def create_budget_task(budget_agent, destination: str, trip_duration: str):
    return Task(
        description=f"Based on the REAL flight options, hotel recommendations, "
                   f"and itinerary created by the other agents, calculate budget...",
        agent=budget_agent,
        # Context automatically includes all previous task outputs
    )
```

What I observed: The agent implicitly receives all previous task results through CrewAI's framework without explicit passing.

---

## My Conclusions: When to Use Each

### I would use AutoGen when:
- âœ… You need fine-grained control over agent interactions
- âœ… Agents need to debate or iterate on ideas
- âœ… The workflow might change based on intermediate results
- âœ… You want agents to explicitly reference each other's work

### I would use CrewAI when:
- âœ… You have a clear, sequential workflow
- âœ… Each agent has distinct, non-overlapping tasks
- âœ… You want less boilerplate code
- âœ… You want to use built-in tools and task management

---

## Final Summary

| Communication Aspect | AutoGen | CrewAI |
|---------------------|---------|---------|
| **How agents "talk"** | Through prompt injection | Through task context |
| **Context passing** | Manual (explicit) | Automatic (implicit) |
| **Code complexity** | More code, more control | Less code, simpler |
| **Best analogy** | Email chain where each person quotes previous emails | Assembly line where each worker builds on previous work |
| **Visibility** | You see exactly what each agent receives | Framework manages behind scenes |
| **Iteration** | Easy to add loops or conditions | Harder - sequential by design |

---

## What I Learned

After running both demos and analyzing the code, I now understand:

- **AutoGen uses explicit context passing** - I have full control over what each agent sees, but I need to write more code to manage it
- **CrewAI uses implicit task dependencies** - The framework handles context automatically, making my code cleaner but giving me less granular control
- **Both approaches work well** - The choice depends on my specific use case and how much control I need over agent interactions

The main insight: **AutoGen feels like a conversation between agents, while CrewAI feels like a structured workflow with specialized workers.**

Both frameworks successfully enable multi-agent collaboration, just with different philosophies and implementation approaches.
